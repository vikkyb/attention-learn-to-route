{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerlise/opt/anaconda3/envs/sadrl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from utils import load_model\n",
    "from problems.tsp.problem_tsp import TSPDataset\n",
    "import time\n",
    "from mcts.mcts_utils import evaluate_tour\n",
    "from eval import get_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS TO BE SET ###\n",
    "n_graphs = 100\n",
    "n_nodes = 100\n",
    "width = 6\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading model from pretrained/tsp_100/epoch-99.pt\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model 20 nodes and set temperature\n",
    "model, _ = load_model(F'pretrained/tsp_{n_nodes}/')\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "# Load test set graphs 20 nodes\n",
    "# If this block does not work, make sure you called:\n",
    "# python generate_data.py --problem all --name test --seed 1234\n",
    "with open(F\"data/tsp/tsp{n_nodes}_test_seed1234.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "    dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "    dataset.size = len(dataset.data)\n",
    "    graphs = []\n",
    "    for sample in dataset.data:\n",
    "        graphs.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy experiments\n",
    "greedy_timestamps = []\n",
    "greedy_results = []\n",
    "\n",
    "for i in range(n_graphs):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    t_s = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[0] - 1):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "            next_node = np.argmax(p)\n",
    "            tour.append(next_node)\n",
    "        t_e = time.perf_counter()\n",
    "        tour.append(0) # Return to the starting position\n",
    "        tour_len = evaluate_tour(graph.numpy(), tour)\n",
    "        greedy_results.append(tour_len)\n",
    "        greedy_timestamps.append(t_e - t_s)\n",
    "        print(\"\\nGraph\", i)\n",
    "        print(evaluate_tour(graph.numpy(), tour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average greedy results 13.369455\n",
      "Average duration 0.04313218084999974\n"
     ]
    }
   ],
   "source": [
    "print(\"Average greedy results\", np.mean(greedy_results))\n",
    "print(\"Average duration\", np.mean(greedy_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results_dict = {\n",
    "    \"greedy_result\" : greedy_results,\n",
    "    \"greedy_timestamps\" : greedy_timestamps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string = F\"experiments/greedy_{n_nodes}.pkl\"\n",
    "with open(save_string, \"wb\") as f:\n",
    "    pickle.dump(greedy_results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam search experiments\n",
    "bs_timestamps = []\n",
    "bs_results = []\n",
    "\n",
    "for i in range(n_graphs):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    t_s = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        cum_log_p, sequences, costs, ids, batch_size = model.beam_search(graph_batch, beam_size=width)\n",
    "        t_e = time.perf_counter()\n",
    "        if sequences is None:\n",
    "            sequences = None\n",
    "            costs = math.inf\n",
    "        else:\n",
    "            sequences, costs = get_best(\n",
    "                sequences.cpu().numpy(), costs.cpu().numpy(),\n",
    "                ids.cpu().numpy() if ids is not None else None,\n",
    "                batch_size\n",
    "            )\n",
    "        tour = sequences[0].tolist()\n",
    "        tour.append(tour[0]) # Return to the starting position\n",
    "        tour_len = evaluate_tour(graph.numpy(), tour)\n",
    "        bs_results.append(tour_len)\n",
    "        bs_timestamps.append(t_e - t_s)\n",
    "        print(\"\\nGraph\", i)\n",
    "        print(tour_len)\n",
    "        print(tour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beam search results 14.617053\n",
      "Average duration 0.11620078358999933\n"
     ]
    }
   ],
   "source": [
    "print(\"Average beam search results\", np.mean(bs_results))\n",
    "print(\"Average duration\", np.mean(bs_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_results_dict = {\n",
    "    \"bs_result\" : bs_results,\n",
    "    \"bs_timestamps\" : bs_timestamps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string = F\"experiments/beam_search_{n_nodes}_{width}.pkl\"\n",
    "with open(save_string, \"wb\") as f:\n",
    "    pickle.dump(bs_results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('sadrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bce899e2f7af33fcdd76036539f31c2932731f2ab16dc95914d450799670bd58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
