{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\envs\\gnn_test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from utils import load_model\n",
    "from problems.tsp.problem_tsp import TSPDataset\n",
    "from utils.mcts import MCTS_TSP, evaluate_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model 20 nodes and set temperature\n",
    "temperature = 1\n",
    "\n",
    "model, _ = load_model('pretrained/tsp_20/')\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set graphs 20 nodes\n",
    "# If this block does not work, make sure you called:\n",
    "# python generate_data.py --problem all --name test --seed 1234\n",
    "with open(\"data/tsp/tsp20_test_seed1234.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "    dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "    dataset.size = len(dataset.data)\n",
    "    graphs = []\n",
    "    for sample in dataset.data:\n",
    "        graphs.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform greedy evaluation on the first n graphs\n",
    "n = 10\n",
    "\n",
    "for i in range(n):\n",
    "    graph = graphs[i][None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[1]):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "            tour.append(np.argmax(p))\n",
    "    print(evaluate_tour(tour), tour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MCTS evaluation on the first n graphs\n",
    "n = 10\n",
    "\n",
    "for i in range(n):\n",
    "    graph = graphs[i][None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    mcts_20_nodes = MCTS_TSP(graph.numpy(), 0, 100, 500, model, \"best\")\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[1]):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "\n",
    "            mcts_20_nodes.update_priors(p)\n",
    "            next_node = mcts_20_nodes.mcts_decide()\n",
    "            tour.append(next_node)\n",
    "\n",
    "    print(evaluate_tour(tour), tour)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('gnn_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f490549c0cd5f8fedcc913b22aef81f15eaa7aa60d2e73329ed2fb30e9ea331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
