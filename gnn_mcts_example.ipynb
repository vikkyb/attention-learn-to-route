{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\envs\\gnn_test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from utils import load_model\n",
    "from problems.tsp.problem_tsp import TSPDataset\n",
    "from utils.mcts_utils import evaluate_tour\n",
    "from mcts.mcts import MCTS_TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading model from pretrained/tsp_20/epoch-99.pt\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model 20 nodes and set temperature\n",
    "temperature = 1\n",
    "\n",
    "model, _ = load_model('pretrained/tsp_20/')\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set graphs 20 nodes\n",
    "# If this block does not work, make sure you called:\n",
    "# python generate_data.py --problem all --name test --seed 1234\n",
    "with open(\"data/tsp/tsp20_test_seed1234.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "    dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "    dataset.size = len(dataset.data)\n",
    "    graphs = []\n",
    "    for sample in dataset.data:\n",
    "        graphs.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.784772947430611 [0, 14, 7, 10, 13, 1, 6, 17, 15, 2, 11, 5, 3, 16, 8, 12, 4, 9, 19, 18, 0]\n",
      "1 4.342111557722092 [0, 5, 10, 4, 18, 2, 15, 9, 8, 7, 13, 17, 1, 3, 19, 14, 12, 16, 6, 11, 0]\n",
      "2 4.117342567071319 [0, 7, 4, 12, 2, 17, 11, 1, 19, 10, 3, 8, 6, 16, 14, 9, 13, 5, 15, 18, 0]\n",
      "3 6.3465187959373 [0, 15, 11, 8, 6, 14, 2, 12, 9, 5, 3, 17, 18, 1, 19, 10, 4, 7, 16, 13, 0]\n",
      "4 5.649249363690615 [0, 7, 8, 1, 2, 4, 19, 11, 5, 14, 3, 10, 9, 17, 16, 13, 6, 12, 18, 15, 0]\n",
      "5 4.553947269916534 [0, 19, 2, 11, 16, 1, 9, 18, 6, 12, 5, 15, 3, 14, 4, 10, 13, 17, 8, 7, 0]\n",
      "6 4.271065201610327 [0, 15, 9, 13, 14, 18, 12, 10, 7, 17, 5, 11, 8, 4, 3, 1, 19, 2, 16, 6, 0]\n",
      "7 5.366192378103733 [0, 16, 17, 11, 2, 4, 14, 19, 3, 6, 9, 12, 7, 1, 15, 8, 18, 10, 5, 13, 0]\n",
      "8 5.081662759184837 [0, 9, 19, 2, 8, 12, 10, 18, 15, 6, 13, 17, 5, 7, 4, 14, 16, 1, 3, 11, 0]\n",
      "9 4.361514372751117 [0, 9, 5, 15, 14, 2, 17, 8, 11, 18, 3, 13, 12, 16, 6, 19, 1, 7, 10, 4, 0]\n",
      "10 4.851467456668615 [0, 9, 16, 11, 19, 8, 12, 6, 2, 4, 10, 14, 5, 7, 13, 18, 1, 3, 15, 17, 0]\n",
      "11 4.209280017763376 [0, 6, 4, 9, 7, 5, 11, 8, 16, 15, 12, 19, 17, 10, 1, 18, 3, 14, 13, 2, 0]\n",
      "12 8.482102379202843 [0, 8, 14, 15, 16, 17, 9, 6, 10, 3, 7, 18, 4, 2, 11, 1, 19, 12, 5, 13, 0]\n",
      "13 3.969079552218318 [0, 18, 2, 14, 9, 4, 5, 16, 7, 1, 3, 10, 12, 15, 8, 13, 19, 11, 17, 6, 0]\n",
      "14 5.768851429224014 [0, 11, 17, 18, 10, 8, 6, 7, 1, 19, 12, 3, 16, 15, 5, 2, 13, 9, 4, 14, 0]\n",
      "15 4.524123247712851 [0, 12, 6, 17, 10, 8, 5, 1, 2, 9, 16, 11, 19, 3, 13, 18, 4, 7, 15, 14, 0]\n",
      "16 6.244031570851803 [0, 19, 2, 16, 6, 9, 17, 12, 3, 7, 11, 14, 4, 5, 13, 8, 15, 10, 1, 18, 0]\n",
      "17 4.792369887698442 [0, 9, 5, 4, 10, 8, 3, 15, 19, 16, 13, 11, 14, 1, 7, 12, 6, 17, 18, 2, 0]\n",
      "18 4.234166696667671 [0, 5, 15, 10, 4, 9, 13, 12, 18, 3, 2, 11, 6, 7, 8, 16, 14, 1, 17, 19, 0]\n",
      "19 3.8638967350125313 [0, 13, 12, 19, 2, 9, 15, 10, 1, 7, 14, 3, 17, 6, 11, 4, 16, 18, 8, 5, 0]\n",
      "20 4.291157923638821 [0, 17, 19, 6, 18, 1, 5, 10, 12, 8, 11, 14, 9, 4, 13, 16, 15, 2, 7, 3, 0]\n",
      "21 5.851491363719106 [0, 4, 13, 16, 9, 12, 1, 3, 18, 17, 2, 6, 5, 19, 7, 8, 14, 11, 15, 10, 0]\n",
      "22 6.182471461594105 [0, 18, 7, 10, 19, 9, 15, 4, 17, 6, 3, 8, 14, 16, 11, 5, 13, 2, 1, 12, 0]\n",
      "23 5.08517536893487 [0, 1, 7, 15, 11, 12, 2, 13, 19, 17, 5, 16, 9, 6, 10, 8, 4, 14, 18, 3, 0]\n",
      "24 7.110320640727878 [0, 17, 9, 18, 2, 19, 7, 13, 3, 1, 6, 8, 4, 11, 15, 16, 14, 5, 10, 12, 0]\n",
      "25 6.004988767206669 [0, 12, 2, 18, 4, 7, 5, 11, 6, 13, 1, 10, 15, 16, 17, 19, 9, 3, 14, 8, 0]\n",
      "26 5.320145256817341 [0, 8, 6, 5, 7, 1, 3, 4, 10, 17, 9, 11, 15, 18, 13, 16, 14, 19, 12, 2, 0]\n",
      "27 4.287363953888416 [0, 2, 4, 14, 9, 7, 19, 6, 1, 16, 10, 12, 18, 15, 5, 3, 8, 13, 11, 17, 0]\n",
      "28 6.050140913575888 [0, 16, 1, 6, 7, 11, 18, 12, 13, 3, 2, 9, 10, 17, 4, 19, 8, 15, 5, 14, 0]\n",
      "29 4.553655482828617 [0, 4, 19, 2, 11, 3, 6, 16, 14, 9, 18, 5, 1, 15, 10, 7, 8, 12, 17, 13, 0]\n",
      "30 4.703372985124588 [0, 3, 6, 4, 1, 7, 8, 17, 16, 12, 19, 14, 13, 5, 10, 18, 2, 11, 15, 9, 0]\n",
      "31 3.629890749230981 [0, 8, 17, 4, 7, 15, 12, 19, 5, 16, 1, 13, 2, 11, 18, 3, 9, 14, 6, 10, 0]\n",
      "32 6.440043184906244 [0, 1, 17, 8, 2, 6, 19, 15, 9, 14, 5, 13, 18, 3, 4, 10, 7, 16, 11, 12, 0]\n",
      "33 4.473045326769352 [0, 9, 4, 13, 14, 19, 11, 12, 15, 6, 1, 3, 10, 17, 16, 2, 18, 8, 5, 7, 0]\n",
      "34 5.026565009728074 [0, 4, 3, 8, 5, 1, 13, 11, 10, 19, 15, 14, 12, 9, 16, 17, 18, 6, 2, 7, 0]\n",
      "35 4.555847771465778 [0, 3, 19, 9, 5, 1, 4, 14, 17, 15, 10, 16, 13, 12, 8, 6, 2, 7, 11, 18, 0]\n",
      "36 4.019388180226088 [0, 7, 9, 10, 19, 15, 3, 11, 14, 8, 13, 17, 5, 18, 4, 1, 2, 12, 6, 16, 0]\n",
      "37 4.776817891746759 [0, 4, 16, 18, 5, 15, 13, 6, 10, 9, 12, 19, 7, 11, 1, 8, 17, 3, 14, 2, 0]\n",
      "38 5.070807483047247 [0, 18, 11, 9, 19, 4, 6, 2, 17, 15, 10, 14, 3, 7, 12, 1, 13, 8, 5, 16, 0]\n",
      "39 5.586182041093707 [0, 9, 4, 5, 12, 8, 3, 19, 15, 11, 18, 2, 1, 7, 13, 14, 16, 17, 10, 6, 0]\n",
      "40 5.436209496110678 [0, 15, 17, 11, 9, 14, 1, 19, 3, 6, 5, 12, 2, 18, 10, 4, 13, 8, 16, 7, 0]\n",
      "41 4.0090105682611465 [0, 5, 14, 19, 16, 18, 8, 13, 4, 7, 15, 1, 17, 3, 11, 10, 6, 9, 12, 2, 0]\n",
      "42 4.314152091741562 [0, 15, 10, 6, 13, 5, 3, 2, 9, 7, 14, 19, 4, 17, 16, 11, 1, 8, 12, 18, 0]\n",
      "43 3.719676710665226 [0, 9, 15, 10, 5, 6, 17, 1, 3, 14, 8, 16, 4, 2, 12, 7, 19, 11, 18, 13, 0]\n",
      "44 4.6794361881911755 [0, 8, 4, 13, 10, 7, 3, 5, 6, 19, 9, 18, 14, 2, 12, 11, 17, 1, 16, 15, 0]\n",
      "45 5.28412152081728 [0, 14, 12, 19, 15, 13, 1, 11, 9, 8, 2, 3, 5, 17, 18, 6, 16, 7, 10, 4, 0]\n",
      "46 4.058368923142552 [0, 12, 6, 10, 9, 7, 8, 18, 4, 1, 14, 13, 2, 5, 19, 11, 16, 3, 15, 17, 0]\n",
      "47 3.72458516061306 [0, 1, 8, 5, 19, 4, 16, 6, 2, 15, 11, 13, 10, 14, 18, 7, 9, 3, 12, 17, 0]\n",
      "48 5.058068603742868 [0, 6, 9, 7, 5, 18, 1, 3, 4, 12, 14, 2, 16, 17, 13, 15, 11, 8, 10, 19, 0]\n",
      "49 8.100692126899958 [0, 8, 9, 12, 17, 4, 2, 10, 15, 13, 3, 11, 1, 16, 14, 5, 7, 19, 6, 18, 0]\n",
      "50 4.854532346129417 [0, 12, 15, 5, 7, 6, 9, 11, 16, 2, 10, 4, 14, 18, 19, 17, 1, 3, 8, 13, 0]\n",
      "51 4.149986010044813 [0, 10, 7, 5, 14, 12, 9, 19, 11, 6, 2, 3, 8, 18, 1, 16, 15, 17, 4, 13, 0]\n",
      "52 4.322531163692474 [0, 4, 12, 16, 5, 2, 3, 1, 10, 11, 14, 7, 18, 13, 6, 8, 15, 9, 19, 17, 0]\n",
      "53 4.112093476578593 [0, 8, 17, 13, 15, 12, 14, 3, 18, 16, 2, 7, 10, 11, 19, 5, 9, 6, 4, 1, 0]\n",
      "54 6.716277290135622 [0, 19, 4, 3, 16, 17, 13, 11, 8, 1, 15, 7, 2, 18, 5, 10, 14, 9, 6, 12, 0]\n",
      "55 4.246302731335163 [0, 3, 2, 18, 12, 6, 10, 16, 13, 11, 4, 19, 15, 7, 5, 9, 8, 1, 17, 14, 0]\n",
      "56 4.250053275376558 [0, 14, 10, 12, 17, 19, 8, 9, 16, 15, 1, 13, 6, 5, 3, 18, 4, 7, 11, 2, 0]\n",
      "57 5.430034328252077 [0, 13, 16, 3, 15, 8, 19, 7, 18, 1, 12, 5, 11, 6, 9, 2, 14, 17, 4, 10, 0]\n",
      "58 6.18358988314867 [0, 18, 11, 8, 1, 5, 19, 14, 6, 2, 17, 10, 9, 16, 15, 7, 4, 3, 13, 12, 0]\n",
      "59 4.09749602060765 [0, 19, 15, 3, 1, 11, 4, 10, 16, 2, 12, 6, 14, 8, 7, 18, 9, 13, 5, 17, 0]\n",
      "60 5.098846472799778 [0, 4, 1, 3, 16, 7, 10, 5, 14, 11, 2, 19, 12, 13, 8, 15, 9, 18, 17, 6, 0]\n",
      "61 6.548871044069529 [0, 4, 7, 19, 12, 2, 10, 17, 14, 11, 1, 13, 16, 15, 6, 5, 18, 8, 3, 9, 0]\n",
      "62 5.215781457722187 [0, 6, 4, 1, 13, 12, 3, 9, 14, 17, 7, 18, 16, 10, 8, 19, 2, 11, 5, 15, 0]\n",
      "63 4.928965996950865 [0, 9, 18, 3, 10, 5, 7, 1, 4, 2, 6, 11, 13, 15, 14, 12, 19, 8, 17, 16, 0]\n",
      "64 4.327565331012011 [0, 2, 12, 4, 8, 13, 19, 9, 11, 15, 16, 3, 5, 18, 10, 17, 14, 7, 1, 6, 0]\n",
      "65 4.536953408736736 [0, 13, 4, 9, 14, 6, 15, 3, 17, 16, 2, 7, 12, 11, 10, 5, 8, 19, 1, 18, 0]\n",
      "66 4.495355501770973 [0, 18, 1, 15, 3, 13, 6, 19, 14, 11, 17, 10, 16, 2, 7, 12, 5, 4, 8, 9, 0]\n",
      "67 4.8511201068758965 [0, 8, 6, 19, 12, 10, 3, 14, 4, 15, 13, 17, 16, 7, 9, 1, 5, 2, 18, 11, 0]\n",
      "68 4.880351305007935 [0, 18, 11, 5, 19, 6, 16, 10, 3, 13, 14, 9, 15, 4, 8, 1, 17, 2, 7, 12, 0]\n",
      "69 3.755350861698389 [0, 15, 4, 9, 6, 11, 7, 3, 10, 13, 12, 14, 16, 1, 8, 19, 2, 17, 18, 5, 0]\n",
      "70 4.489054221659899 [0, 1, 11, 19, 3, 14, 16, 4, 2, 13, 18, 17, 7, 12, 15, 6, 10, 8, 9, 5, 0]\n",
      "71 4.609840080142021 [0, 7, 13, 18, 14, 6, 17, 5, 12, 15, 19, 16, 9, 10, 4, 11, 8, 2, 1, 3, 0]\n",
      "72 4.891629997640848 [0, 14, 17, 3, 4, 15, 1, 8, 18, 11, 5, 7, 2, 9, 16, 12, 10, 19, 13, 6, 0]\n",
      "73 3.897756990045309 [0, 4, 14, 10, 19, 6, 9, 13, 15, 1, 17, 8, 2, 11, 18, 3, 5, 7, 16, 12, 0]\n",
      "74 4.337130423635244 [0, 13, 15, 10, 5, 11, 1, 3, 2, 12, 19, 14, 18, 6, 9, 4, 16, 17, 8, 7, 0]\n",
      "75 4.4897998329252005 [0, 9, 10, 16, 6, 11, 8, 12, 5, 13, 14, 17, 4, 19, 18, 15, 1, 2, 3, 7, 0]\n",
      "76 3.4614908397197723 [0, 7, 11, 16, 17, 15, 1, 14, 4, 19, 8, 5, 12, 18, 13, 3, 9, 6, 10, 2, 0]\n",
      "77 4.288288971409202 [0, 12, 7, 2, 18, 9, 3, 10, 8, 14, 6, 11, 19, 1, 16, 15, 13, 17, 5, 4, 0]\n",
      "78 5.175541568547487 [0, 2, 12, 5, 4, 18, 10, 17, 13, 11, 14, 6, 3, 15, 7, 9, 1, 19, 8, 16, 0]\n",
      "79 5.549146585166454 [0, 6, 5, 13, 18, 16, 11, 17, 7, 2, 10, 4, 3, 1, 15, 12, 8, 9, 19, 14, 0]\n",
      "80 4.332348215393722 [0, 12, 7, 1, 18, 5, 13, 15, 2, 19, 14, 3, 6, 8, 17, 10, 4, 16, 11, 9, 0]\n",
      "81 4.092862572520971 [0, 9, 4, 10, 1, 5, 13, 3, 14, 7, 15, 19, 2, 8, 6, 11, 12, 16, 17, 18, 0]\n",
      "82 6.253494068980217 [0, 7, 2, 3, 11, 1, 18, 6, 19, 10, 12, 14, 16, 4, 9, 5, 15, 17, 8, 13, 0]\n",
      "83 6.165169715881348 [0, 14, 13, 1, 3, 7, 10, 9, 8, 2, 19, 17, 18, 16, 11, 15, 4, 5, 6, 12, 0]\n",
      "84 4.529483459889889 [0, 7, 2, 19, 6, 14, 18, 15, 10, 13, 1, 16, 9, 12, 8, 11, 3, 5, 17, 4, 0]\n",
      "85 6.84093638882041 [0, 17, 2, 3, 14, 6, 10, 18, 4, 1, 19, 15, 9, 8, 16, 7, 5, 11, 13, 12, 0]\n",
      "86 5.3811964355409145 [0, 10, 12, 4, 16, 1, 2, 15, 13, 18, 6, 17, 11, 8, 7, 5, 14, 3, 19, 9, 0]\n",
      "87 4.55626181140542 [0, 9, 15, 8, 6, 16, 14, 13, 4, 10, 12, 19, 1, 3, 17, 5, 2, 11, 7, 18, 0]\n",
      "88 4.7209256291389465 [0, 18, 14, 11, 16, 6, 19, 7, 13, 5, 9, 1, 15, 10, 12, 2, 4, 3, 17, 8, 0]\n",
      "89 4.767574435099959 [0, 5, 17, 8, 9, 11, 19, 12, 18, 6, 2, 13, 4, 1, 15, 16, 10, 14, 3, 7, 0]\n",
      "90 4.66594871878624 [0, 5, 1, 7, 10, 12, 15, 9, 16, 4, 13, 17, 2, 8, 14, 11, 6, 18, 19, 3, 0]\n",
      "91 6.692270711064339 [0, 17, 18, 11, 16, 13, 4, 5, 8, 2, 6, 12, 9, 19, 1, 3, 15, 14, 7, 10, 0]\n",
      "92 3.302637320011854 [0, 6, 2, 14, 19, 18, 1, 13, 10, 11, 7, 15, 8, 17, 9, 12, 5, 16, 3, 4, 0]\n",
      "93 4.842186136171222 [0, 4, 13, 9, 1, 17, 2, 6, 16, 10, 19, 14, 5, 7, 3, 15, 18, 11, 12, 8, 0]\n",
      "94 4.685582734644413 [0, 10, 4, 6, 11, 13, 14, 5, 8, 18, 19, 9, 2, 12, 15, 17, 1, 3, 16, 7, 0]\n",
      "95 4.898825187236071 [0, 11, 14, 15, 2, 8, 9, 16, 19, 4, 7, 1, 12, 10, 5, 3, 18, 6, 17, 13, 0]\n",
      "96 3.9964575581252575 [0, 12, 17, 3, 14, 9, 5, 8, 18, 19, 15, 11, 2, 6, 1, 4, 16, 13, 10, 7, 0]\n",
      "97 5.0970015078783035 [0, 15, 16, 14, 1, 9, 18, 7, 12, 5, 17, 4, 10, 8, 19, 13, 2, 11, 3, 6, 0]\n",
      "98 4.02394761890173 [0, 18, 6, 19, 2, 1, 13, 15, 14, 7, 8, 3, 11, 12, 9, 17, 5, 16, 4, 10, 0]\n",
      "99 4.518144881352782 [0, 18, 13, 12, 5, 4, 16, 17, 9, 14, 7, 15, 6, 11, 8, 1, 3, 19, 2, 10, 0]\n",
      "4.927719319625758\n"
     ]
    }
   ],
   "source": [
    "# Perform greedy evaluation on the first n graphs\n",
    "n = 100\n",
    "total_len = 0\n",
    "for i in range(n):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[0] - 1):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "            tour.append(np.argmax(p))\n",
    "        tour.append(0) # Return to the starting position\n",
    "        print(i, evaluate_tour(graph.numpy(), tour), tour)\n",
    "        total_len += evaluate_tour(graph.numpy(), tour)\n",
    "print(total_len/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.146226655691862 [0, 19, 1, 13, 11, 3, 15, 6, 8, 2, 16, 12, 4, 9, 17, 18, 10, 7, 5, 14, 0]\n",
      "1 4.463504403829575 [0, 19, 5, 3, 1, 2, 15, 8, 9, 7, 13, 17, 10, 18, 4, 11, 16, 6, 12, 14, 0]\n",
      "2 5.051968475803733 [0, 16, 8, 6, 1, 19, 2, 17, 12, 11, 10, 3, 14, 9, 13, 5, 15, 18, 4, 7, 0]\n",
      "3 5.829832036048174 [0, 14, 2, 7, 16, 10, 3, 9, 5, 4, 12, 6, 13, 8, 11, 15, 1, 19, 17, 18, 0]\n",
      "4 4.874682184308767 [0, 4, 1, 2, 19, 11, 6, 7, 16, 8, 13, 9, 5, 10, 3, 14, 15, 18, 12, 17, 0]\n",
      "5 6.993110969662666 [0, 19, 9, 15, 6, 2, 1, 3, 12, 14, 10, 7, 17, 8, 13, 4, 5, 18, 16, 11, 0]\n",
      "6 5.77114150300622 [0, 11, 8, 5, 15, 13, 9, 1, 4, 3, 19, 2, 10, 14, 18, 12, 17, 7, 6, 16, 0]\n",
      "7 4.75518112257123 [0, 16, 17, 11, 7, 2, 14, 4, 12, 1, 9, 15, 19, 3, 6, 8, 18, 10, 5, 13, 0]\n",
      "8 6.1930660754442215 [0, 16, 1, 2, 11, 7, 4, 14, 17, 5, 13, 15, 6, 18, 10, 12, 8, 19, 3, 9, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m p \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     33\u001b[0m mcts_20_nodes\u001b[39m.\u001b[39mupdate_priors(p)\n\u001b[1;32m---> 34\u001b[0m next_node \u001b[39m=\u001b[39m mcts_20_nodes\u001b[39m.\u001b[39;49mmcts_decide()\n\u001b[0;32m     35\u001b[0m \u001b[39m# print(\"N children\", mcts_20_nodes.root._children.keys())\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# print(p)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m tour\u001b[39m.\u001b[39mappend(next_node)\n",
      "File \u001b[1;32mc:\\Users\\victo\\Documents\\Uni\\SADRL\\gnn_mcts_2\\attention-learn-to-route\\mcts\\mcts.py:63\u001b[0m, in \u001b[0;36mMCTS_TSP.mcts_decide\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m selected_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mselect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_mode)\n\u001b[0;32m     62\u001b[0m selected_node\u001b[39m.\u001b[39mexpand()\n\u001b[1;32m---> 63\u001b[0m outcome \u001b[39m=\u001b[39m selected_node\u001b[39m.\u001b[39;49mrollout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_rollout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_mode)\n\u001b[0;32m     64\u001b[0m selected_node\u001b[39m.\u001b[39mupdate_recursive(outcome)\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmin([outcome, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score])\n",
      "File \u001b[1;32mc:\\Users\\victo\\Documents\\Uni\\SADRL\\gnn_mcts_2\\attention-learn-to-route\\mcts\\mcts_node.py:124\u001b[0m, in \u001b[0;36mMCTS_node.rollout\u001b[1;34m(self, n_rollouts, eval_mode)\u001b[0m\n\u001b[0;32m    122\u001b[0m rollout_outcomes \u001b[39m=\u001b[39m []\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_rollouts):\n\u001b[1;32m--> 124\u001b[0m     rollout_outcomes\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_rollout())\n\u001b[0;32m    125\u001b[0m \u001b[39mif\u001b[39;00m eval_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(rollout_outcomes)\n\u001b[0;32m    126\u001b[0m \u001b[39melif\u001b[39;00m eval_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmin(rollout_outcomes)\n",
      "File \u001b[1;32mc:\\Users\\victo\\Documents\\Uni\\SADRL\\gnn_mcts_2\\attention-learn-to-route\\mcts\\mcts_node.py:142\u001b[0m, in \u001b[0;36mMCTS_node.one_rollout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(copy_available_nodes)\n\u001b[0;32m    140\u001b[0m new_tour \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtour \u001b[39m+\u001b[39m copy_available_nodes \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtour[\u001b[39m0\u001b[39m]] \u001b[39m# DO NOT FORGET TO FINISH ON THE NODE WE STARTED ON\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m new_tour_length \u001b[39m=\u001b[39m evaluate_tour(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph, new_tour)\n\u001b[0;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m new_tour_length\n",
      "File \u001b[1;32mc:\\Users\\victo\\Documents\\Uni\\SADRL\\gnn_mcts_2\\attention-learn-to-route\\utils\\mcts_utils.py:41\u001b[0m, in \u001b[0;36mevaluate_tour\u001b[1;34m(graph, tour)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m i, node \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tour):\n\u001b[0;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(tour) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     40\u001b[0m         \u001b[39m# Simple Euclidean distance\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m         tour_length \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(graph[node] \u001b[39m-\u001b[39;49m graph[tour[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]])\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m tour_length\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\victo\\anaconda3\\envs\\gnn_test\\lib\\site-packages\\numpy\\linalg\\linalg.py:2526\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2524\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2526\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[0;32m   2527\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform MCTS evaluation on the first n graphs\n",
    "n = 10\n",
    "total_len = 0\n",
    "for i in range(n):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    mcts_20_nodes = MCTS_TSP(graph.numpy(), 0, 50, 50, model, \"best\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[0] - 1):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "\n",
    "            mcts_20_nodes.update_priors(p)\n",
    "            next_node = mcts_20_nodes.mcts_decide()\n",
    "            # print(\"N children\", mcts_20_nodes.root._children.keys())\n",
    "            # print(p)\n",
    "            tour.append(next_node)\n",
    "            mcts_20_nodes.move_to(next_node)\n",
    "        \n",
    "        tour.append(0) # Return to the starting position\n",
    "        print(i, evaluate_tour(graph.numpy(), tour), tour)\n",
    "        total_len += evaluate_tour(graph.numpy(), tour)\n",
    "        # break\n",
    "print(total_len/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.927719319625758\n",
    "5.103555862233042"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('gnn_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f490549c0cd5f8fedcc913b22aef81f15eaa7aa60d2e73329ed2fb30e9ea331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
