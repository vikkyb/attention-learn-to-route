{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Anaconda\\envs\\ReinforcementLearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from utils import load_model\n",
    "from problems.tsp.problem_tsp import TSPDataset\n",
    "import time\n",
    "from mcts.mcts import MCTS_TSP\n",
    "from mcts.mcts_utils import evaluate_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS TO BE SET ###\n",
    "n_graphs = 10\n",
    "n_nodes = 20\n",
    "\n",
    "n_expansions = 100\n",
    "n_rollouts = 100\n",
    "eval_selection = \"best\"\n",
    "eval_rollout = \"best\"\n",
    "\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load model 20 nodes and set temperature\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model, _ \u001b[39m=\u001b[39m load_model(\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpretrained/tsp_\u001b[39m\u001b[39m{\u001b[39;00mn_nodes\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel loaded\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Load model 20 nodes and set temperature\n",
    "model, _ = load_model(F'pretrained/tsp_{n_nodes}/')\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "# Load test set graphs 20 nodes\n",
    "# If this block does not work, make sure you called:\n",
    "# python generate_data.py --problem all --name test --seed 1234\n",
    "with open(F\"data/tsp/tsp{n_nodes}_test_seed1234.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "    dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "    dataset.size = len(dataset.data)\n",
    "    graphs = []\n",
    "    for sample in dataset.data:\n",
    "        graphs.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph 0\n",
      "4.8627996\n",
      "Best tour seen 4.727939\n",
      "\n",
      "Graph 1\n",
      "5.3296275\n",
      "Best tour seen 5.174877\n",
      "\n",
      "Graph 2\n",
      "5.0051584\n",
      "Best tour seen 4.987064\n",
      "\n",
      "Graph 3\n",
      "5.063277\n",
      "Best tour seen 5.063277\n",
      "\n",
      "Graph 4\n",
      "4.360171\n",
      "Best tour seen 4.2643023\n",
      "\n",
      "Graph 5\n",
      "4.9554367\n",
      "Best tour seen 4.9554367\n",
      "\n",
      "Graph 6\n",
      "5.14106\n",
      "Best tour seen 4.830803\n",
      "\n",
      "Graph 7\n",
      "4.5489144\n",
      "Best tour seen 4.5489144\n",
      "\n",
      "Graph 8\n",
      "5.4290514\n",
      "Best tour seen 5.4290514\n",
      "\n",
      "Graph 9\n",
      "4.7659144\n",
      "Best tour seen 4.765914\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "total_len_best_seen = 0\n",
    "\n",
    "mcts_timestamps = []\n",
    "mcts_results = []\n",
    "best_seen_results = []\n",
    "\n",
    "for i in range(n_graphs):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    mcts_20_nodes = MCTS_TSP(graph.numpy(), 0, n_expansions, n_rollouts, eval_selection=\"best\", eval_rollout=\"mean\")\n",
    "    t_s = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[0] - 1):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "            mcts_20_nodes.update_priors(p)\n",
    "            next_node = mcts_20_nodes.mcts_decide()\n",
    "            # print(\"N children\", mcts_20_nodes.root._children.keys())\n",
    "            # print(p)\n",
    "            tour.append(next_node)\n",
    "            mcts_20_nodes.move_to(next_node)\n",
    "        t_e = time.perf_counter()\n",
    "        tour.append(0) # Return to the starting position\n",
    "        tour_len = evaluate_tour(graph.numpy(), tour)\n",
    "        mcts_results.append(tour_len)\n",
    "        best_seen_results.append(mcts_20_nodes.best_seen_length)\n",
    "        mcts_timestamps.append(t_e - t_s)\n",
    "        print(\"\\nGraph\", i)\n",
    "        print(evaluate_tour(graph.numpy(), tour))\n",
    "        print(\"Best tour seen\", mcts_20_nodes.best_seen_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MCTS results 4.946141\n",
      "Average best seen results 4.874758\n",
      "Average duration 7.104339689999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Average MCTS results\", np.mean(mcts_results))\n",
    "print(\"Average best seen results\", np.mean(best_seen_results))\n",
    "print(\"Average duration\", np.mean(mcts_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"mcts_result\" : mcts_results,\n",
    "    \"best_seen_results\" : best_seen_results,\n",
    "    \"mcts_timestamps\" : mcts_timestamps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/20_10_100_100_best_best.pkl\n"
     ]
    }
   ],
   "source": [
    "save_string = F\"experiments/{n_nodes}_{n_graphs}_{n_expansions}_{n_rollouts}_{eval_selection}_{eval_rollout}.pkl\"\n",
    "# print(save_string)\n",
    "with open(save_string, \"wb\") as f:\n",
    "    pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this for experiment loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading model from pretrained/tsp_50/epoch-99.pt\n",
      "model loaded\n",
      "\n",
      "Graph 0 100 100\n",
      "\n",
      "Graph 1 100 100\n",
      "\n",
      "Graph 2 100 100\n",
      "\n",
      "Graph 3 100 100\n",
      "\n",
      "Graph 4 100 100\n",
      "\n",
      "Graph 5 100 100\n",
      "\n",
      "Graph 6 100 100\n",
      "\n",
      "Graph 7 100 100\n",
      "\n",
      "Graph 8 100 100\n",
      "\n",
      "Graph 9 100 100\n",
      "\n",
      "Graph 10 100 100\n",
      "\n",
      "Graph 11 100 100\n",
      "\n",
      "Graph 12 100 100\n",
      "\n",
      "Graph 13 100 100\n",
      "\n",
      "Graph 14 100 100\n",
      "\n",
      "Graph 15 100 100\n",
      "\n",
      "Graph 16 100 100\n",
      "\n",
      "Graph 17 100 100\n",
      "\n",
      "Graph 18 100 100\n",
      "\n",
      "Graph 19 100 100\n",
      "\n",
      "Graph 20 100 100\n",
      "\n",
      "Graph 21 100 100\n",
      "\n",
      "Graph 22 100 100\n",
      "\n",
      "Graph 23 100 100\n",
      "\n",
      "Graph 24 100 100\n",
      "\n",
      "Graph 25 100 100\n",
      "\n",
      "Graph 26 100 100\n",
      "\n",
      "Graph 27 100 100\n",
      "\n",
      "Graph 28 100 100\n",
      "\n",
      "Graph 29 100 100\n",
      "\n",
      "Graph 30 100 100\n",
      "\n",
      "Graph 31 100 100\n",
      "\n",
      "Graph 32 100 100\n",
      "\n",
      "Graph 33 100 100\n",
      "\n",
      "Graph 34 100 100\n",
      "\n",
      "Graph 35 100 100\n",
      "\n",
      "Graph 36 100 100\n",
      "\n",
      "Graph 37 100 100\n",
      "\n",
      "Graph 38 100 100\n",
      "\n",
      "Graph 39 100 100\n",
      "\n",
      "Graph 40 100 100\n",
      "\n",
      "Graph 41 100 100\n",
      "\n",
      "Graph 42 100 100\n",
      "\n",
      "Graph 43 100 100\n",
      "\n",
      "Graph 44 100 100\n",
      "\n",
      "Graph 45 100 100\n",
      "\n",
      "Graph 46 100 100\n",
      "\n",
      "Graph 47 100 100\n",
      "\n",
      "Graph 48 100 100\n",
      "\n",
      "Graph 49 100 100\n",
      "\n",
      "Graph 50 100 100\n",
      "\n",
      "Graph 51 100 100\n",
      "\n",
      "Graph 52 100 100\n",
      "\n",
      "Graph 53 100 100\n",
      "\n",
      "Graph 54 100 100\n",
      "\n",
      "Graph 55 100 100\n",
      "\n",
      "Graph 56 100 100\n",
      "\n",
      "Graph 57 100 100\n",
      "\n",
      "Graph 58 100 100\n",
      "\n",
      "Graph 59 100 100\n",
      "\n",
      "Graph 60 100 100\n",
      "\n",
      "Graph 61 100 100\n",
      "\n",
      "Graph 62 100 100\n",
      "\n",
      "Graph 63 100 100\n",
      "\n",
      "Graph 64 100 100\n",
      "\n",
      "Graph 65 100 100\n",
      "\n",
      "Graph 66 100 100\n",
      "\n",
      "Graph 67 100 100\n",
      "\n",
      "Graph 68 100 100\n",
      "\n",
      "Graph 69 100 100\n",
      "\n",
      "Graph 70 100 100\n",
      "\n",
      "Graph 71 100 100\n",
      "\n",
      "Graph 72 100 100\n",
      "\n",
      "Graph 73 100 100\n",
      "\n",
      "Graph 74 100 100\n",
      "\n",
      "Graph 75 100 100\n",
      "\n",
      "Graph 76 100 100\n",
      "\n",
      "Graph 77 100 100\n",
      "\n",
      "Graph 78 100 100\n",
      "\n",
      "Graph 79 100 100\n",
      "\n",
      "Graph 80 100 100\n",
      "\n",
      "Graph 81 100 100\n",
      "\n",
      "Graph 82 100 100\n",
      "\n",
      "Graph 83 100 100\n",
      "\n",
      "Graph 84 100 100\n",
      "\n",
      "Graph 85 100 100\n",
      "\n",
      "Graph 86 100 100\n",
      "\n",
      "Graph 87 100 100\n",
      "\n",
      "Graph 88 100 100\n",
      "\n",
      "Graph 89 100 100\n",
      "\n",
      "Graph 90 100 100\n",
      "\n",
      "Graph 91 100 100\n",
      "\n",
      "Graph 92 100 100\n",
      "\n",
      "Graph 93 100 100\n",
      "\n",
      "Graph 94 100 100\n",
      "\n",
      "Graph 95 100 100\n",
      "\n",
      "Graph 96 100 100\n",
      "\n",
      "Graph 97 100 100\n",
      "\n",
      "Graph 98 100 100\n",
      "\n",
      "Graph 99 100 100\n",
      "  [*] Loading model from pretrained/tsp_100/epoch-99.pt\n",
      "model loaded\n",
      "\n",
      "Graph 0 100 100\n",
      "\n",
      "Graph 1 100 100\n",
      "\n",
      "Graph 2 100 100\n",
      "\n",
      "Graph 3 100 100\n",
      "\n",
      "Graph 4 100 100\n",
      "\n",
      "Graph 5 100 100\n",
      "\n",
      "Graph 6 100 100\n",
      "\n",
      "Graph 7 100 100\n",
      "\n",
      "Graph 8 100 100\n",
      "\n",
      "Graph 9 100 100\n",
      "\n",
      "Graph 10 100 100\n",
      "\n",
      "Graph 11 100 100\n",
      "\n",
      "Graph 12 100 100\n",
      "\n",
      "Graph 13 100 100\n",
      "\n",
      "Graph 14 100 100\n",
      "\n",
      "Graph 15 100 100\n",
      "\n",
      "Graph 16 100 100\n",
      "\n",
      "Graph 17 100 100\n",
      "\n",
      "Graph 18 100 100\n",
      "\n",
      "Graph 19 100 100\n",
      "\n",
      "Graph 20 100 100\n",
      "\n",
      "Graph 21 100 100\n",
      "\n",
      "Graph 22 100 100\n",
      "\n",
      "Graph 23 100 100\n",
      "\n",
      "Graph 24 100 100\n",
      "\n",
      "Graph 25 100 100\n",
      "\n",
      "Graph 26 100 100\n",
      "\n",
      "Graph 27 100 100\n",
      "\n",
      "Graph 28 100 100\n",
      "\n",
      "Graph 29 100 100\n",
      "\n",
      "Graph 30 100 100\n",
      "\n",
      "Graph 31 100 100\n",
      "\n",
      "Graph 32 100 100\n",
      "\n",
      "Graph 33 100 100\n",
      "\n",
      "Graph 34 100 100\n",
      "\n",
      "Graph 35 100 100\n",
      "\n",
      "Graph 36 100 100\n",
      "\n",
      "Graph 37 100 100\n",
      "\n",
      "Graph 38 100 100\n",
      "\n",
      "Graph 39 100 100\n",
      "\n",
      "Graph 40 100 100\n",
      "\n",
      "Graph 41 100 100\n",
      "\n",
      "Graph 42 100 100\n",
      "\n",
      "Graph 43 100 100\n",
      "\n",
      "Graph 44 100 100\n",
      "\n",
      "Graph 45 100 100\n",
      "\n",
      "Graph 46 100 100\n",
      "\n",
      "Graph 47 100 100\n",
      "\n",
      "Graph 48 100 100\n",
      "\n",
      "Graph 49 100 100\n",
      "\n",
      "Graph 50 100 100\n",
      "\n",
      "Graph 51 100 100\n",
      "\n",
      "Graph 52 100 100\n",
      "\n",
      "Graph 53 100 100\n",
      "\n",
      "Graph 54 100 100\n",
      "\n",
      "Graph 55 100 100\n",
      "\n",
      "Graph 56 100 100\n",
      "\n",
      "Graph 57 100 100\n",
      "\n",
      "Graph 58 100 100\n",
      "\n",
      "Graph 59 100 100\n",
      "\n",
      "Graph 60 100 100\n",
      "\n",
      "Graph 61 100 100\n",
      "\n",
      "Graph 62 100 100\n",
      "\n",
      "Graph 63 100 100\n",
      "\n",
      "Graph 64 100 100\n",
      "\n",
      "Graph 65 100 100\n",
      "\n",
      "Graph 66 100 100\n",
      "\n",
      "Graph 67 100 100\n",
      "\n",
      "Graph 68 100 100\n",
      "\n",
      "Graph 69 100 100\n",
      "\n",
      "Graph 70 100 100\n",
      "\n",
      "Graph 71 100 100\n",
      "\n",
      "Graph 72 100 100\n",
      "\n",
      "Graph 73 100 100\n",
      "\n",
      "Graph 74 100 100\n",
      "\n",
      "Graph 75 100 100\n",
      "\n",
      "Graph 76 100 100\n",
      "\n",
      "Graph 77 100 100\n",
      "\n",
      "Graph 78 100 100\n",
      "\n",
      "Graph 79 100 100\n",
      "\n",
      "Graph 80 100 100\n",
      "\n",
      "Graph 81 100 100\n",
      "\n",
      "Graph 82 100 100\n",
      "\n",
      "Graph 83 100 100\n",
      "\n",
      "Graph 84 100 100\n",
      "\n",
      "Graph 85 100 100\n",
      "\n",
      "Graph 86 100 100\n",
      "\n",
      "Graph 87 100 100\n",
      "\n",
      "Graph 88 100 100\n",
      "\n",
      "Graph 89 100 100\n",
      "\n",
      "Graph 90 100 100\n",
      "\n",
      "Graph 91 100 100\n",
      "\n",
      "Graph 92 100 100\n",
      "\n",
      "Graph 93 100 100\n",
      "\n",
      "Graph 94 100 100\n",
      "\n",
      "Graph 95 100 100\n",
      "\n",
      "Graph 96 100 100\n",
      "\n",
      "Graph 97 100 100\n",
      "\n",
      "Graph 98 100 100\n",
      "\n",
      "Graph 99 100 100\n"
     ]
    }
   ],
   "source": [
    "### PARAMETERS TO BE SET ###\n",
    "n_graphs = 100\n",
    "n_nodes = 20\n",
    "\n",
    "n_expansions = 100\n",
    "n_rollouts = 100\n",
    "eval_selection = \"mean\"\n",
    "eval_rollout = \"mean\"\n",
    "\n",
    "temperature = 1\n",
    "\n",
    "for n_nodes in [50, 100]:\n",
    "    # Load model 20 nodes and set temperature\n",
    "    model, _ = load_model(F'pretrained/tsp_{n_nodes}/')\n",
    "    model.eval()\n",
    "    print(\"model loaded\")\n",
    "    # Load test set graphs 20 nodes\n",
    "    # If this block does not work, make sure you called:\n",
    "    # python generate_data.py --problem all --name test --seed 1234\n",
    "    with open(F\"data/tsp/tsp{n_nodes}_test_seed1234.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "        dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "        dataset.size = len(dataset.data)\n",
    "        graphs = []\n",
    "        for sample in dataset.data:\n",
    "            graphs.append(sample)\n",
    "\n",
    "\n",
    "\n",
    "    # for n_rollouts in [50, 150, 500]:\n",
    "    #     for n_expansions in [50, 150, 500]:\n",
    "    total_len = 0\n",
    "    total_len_best_seen = 0\n",
    "\n",
    "    mcts_timestamps = []\n",
    "    mcts_results = []\n",
    "    best_seen_results = []\n",
    "\n",
    "    for i in range(n_graphs):\n",
    "        graph = graphs[i]\n",
    "        graph_batch = graph[None] # Add batch dimension\n",
    "        tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "        mcts_20_nodes = MCTS_TSP(graph.numpy(), 0, n_expansions, n_rollouts, eval_selection=eval_selection, eval_rollout=eval_rollout)\n",
    "        t_s = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "            # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "            fixed = model._precompute(embeddings)\n",
    "            for visit in range(graph.shape[0] - 1):\n",
    "                tour_tensor = torch.tensor(tour).long()\n",
    "                if len(tour_tensor) == 0:\n",
    "                    step_context = model.W_placeholder\n",
    "                else:\n",
    "                    step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                            embeddings[0, tour_tensor[-1]]), -1)\n",
    "                query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "                mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "                mask[tour_tensor] = 1\n",
    "                mask = mask[None, None, :]\n",
    "\n",
    "                log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "                p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "                assert (p[tour_tensor] == 0).all()\n",
    "                assert (p.sum() - 1).abs() < 1e-5\n",
    "                p = p.numpy()\n",
    "                mcts_20_nodes.update_priors(p)\n",
    "                next_node = mcts_20_nodes.mcts_decide()\n",
    "                # print(\"N children\", mcts_20_nodes.root._children.keys())\n",
    "                # print(p)\n",
    "                tour.append(next_node)\n",
    "                mcts_20_nodes.move_to(next_node)\n",
    "            t_e = time.perf_counter()\n",
    "            tour.append(0) # Return to the starting position\n",
    "            tour_len = evaluate_tour(graph.numpy(), tour)\n",
    "            mcts_results.append(tour_len)\n",
    "            best_seen_results.append(mcts_20_nodes.best_seen_length)\n",
    "            mcts_timestamps.append(t_e - t_s)\n",
    "            print(\"\\nGraph\", i, n_rollouts, n_expansions)\n",
    "            # print(evaluate_tour(graph.numpy(), tour))\n",
    "            # print(\"Best tour seen\", mcts_20_nodes.best_seen_length)\n",
    "\n",
    "    results_dict = {\n",
    "    \"mcts_result\" : mcts_results,\n",
    "    \"best_seen_results\" : best_seen_results,\n",
    "    \"mcts_timestamps\" : mcts_timestamps\n",
    "    }\n",
    "\n",
    "    save_string = F\"experiments/{n_nodes}_{n_graphs}_{n_expansions}_{n_rollouts}_{eval_selection}_{eval_rollout}.pkl\"\n",
    "    # print(save_string)\n",
    "    with open(save_string, \"wb\") as f:\n",
    "        pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"experiments\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "for f in os.listdir(directory):\n",
    "    file = os.path.join(directory, f)\n",
    "    if os.path.isfile(file):\n",
    "        with open(file, \"rb\") as handle:\n",
    "            results[f] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100_100_100_100_mean_mean.pkl \t [14.566  0.859] [14.504  0.848] \tTime: [33.327  1.18 ]\n",
      "20_100_100_100_best_best.pkl \t [5.679 0.671] [5.585 0.619] \tTime: [4.996 0.114]\n",
      "20_100_100_100_best_mean.pkl \t [4.851 0.513] [4.685 0.484] \tTime: [4.992 0.111]\n",
      "20_100_100_100_mean_best.pkl \t [5.043 0.637] [4.781 0.51 ] \tTime: [5.058 0.089]\n",
      "20_100_100_100_mean_mean.pkl \t [4.373 0.437] [4.238 0.398] \tTime: [5.119 0.362]\n",
      "20_100_150_150_mean_mean.pkl \t [4.296 0.452] [4.166 0.402] \tTime: [10.005  0.398]\n",
      "20_100_150_500_mean_mean.pkl \t [4.307 0.404] [4.125 0.35 ] \tTime: [30.427  1.835]\n",
      "20_100_150_50_mean_mean.pkl \t [4.317 0.446] [4.188 0.379] \tTime: [4.458 0.251]\n",
      "20_100_500_150_mean_mean.pkl \t [4.197 0.38 ] [4.045 0.318] \tTime: [31.64   1.361]\n",
      "20_100_500_500_mean_mean.pkl \t [4.169 0.374] [4.034 0.318] \tTime: [95.81   2.612]\n",
      "20_100_500_50_mean_mean.pkl \t [4.203 0.36 ] [4.061 0.317] \tTime: [13.678  0.516]\n",
      "20_100_50_150_mean_mean.pkl \t [4.537 0.461] [4.399 0.412] \tTime: [3.867 0.119]\n",
      "20_100_50_500_mean_mean.pkl \t [4.532 0.445] [4.355 0.394] \tTime: [10.818  0.437]\n",
      "20_100_50_50_mean_mean.pkl \t [4.582 0.53 ] [4.43  0.462] \tTime: [1.872 0.185]\n",
      "50_100_100_100_mean_mean.pkl \t [8.23  0.628] [8.116 0.604] \tTime: [15.109  0.801]\n",
      "50_100_50_50_mean_mean.pkl \t [9.87  0.921] [9.743 0.923] \tTime: [3.877 0.615]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mcts_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m results:\n\u001b[0;32m      2\u001b[0m \u001b[39m#     print(i)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbenchmark\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m i:\n\u001b[1;32m----> 4\u001b[0m         mcts_mean_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround((np\u001b[39m.\u001b[39mmean(results[i][\u001b[39m'\u001b[39;49m\u001b[39mmcts_result\u001b[39;49m\u001b[39m'\u001b[39;49m]), np\u001b[39m.\u001b[39mstd(results[i][\u001b[39m'\u001b[39m\u001b[39mmcts_result\u001b[39m\u001b[39m'\u001b[39m])), \u001b[39m3\u001b[39m)\n\u001b[0;32m      5\u001b[0m         best_seen_mean_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround((np\u001b[39m.\u001b[39mmean(results[i][\u001b[39m'\u001b[39m\u001b[39mbest_seen_results\u001b[39m\u001b[39m'\u001b[39m]), np\u001b[39m.\u001b[39mstd(results[i][\u001b[39m'\u001b[39m\u001b[39mbest_seen_results\u001b[39m\u001b[39m'\u001b[39m])), \u001b[39m3\u001b[39m)\n\u001b[0;32m      6\u001b[0m         time_mean_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround((np\u001b[39m.\u001b[39mmean(results[i][\u001b[39m'\u001b[39m\u001b[39mmcts_timestamps\u001b[39m\u001b[39m'\u001b[39m]), np\u001b[39m.\u001b[39mstd(results[i][\u001b[39m'\u001b[39m\u001b[39mmcts_timestamps\u001b[39m\u001b[39m'\u001b[39m])), \u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mcts_result'"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "#     print(i)\n",
    "    if \"benchmark\" not in i:\n",
    "        mcts_mean_std = np.around((np.mean(results[i]['mcts_result']), np.std(results[i]['mcts_result'])), 3)\n",
    "        best_seen_mean_std = np.around((np.mean(results[i]['best_seen_results']), np.std(results[i]['best_seen_results'])), 3)\n",
    "        time_mean_std = np.around((np.mean(results[i]['mcts_timestamps']), np.std(results[i]['mcts_timestamps'])), 3)\n",
    "#         print(i[:-4], F\"\\tmcts {mcts_mean_std[0]} \\tstd {mcts_mean_std[1]} \\t\\tbest {best_seen_mean_std[0]} \\tstd {best_seen_mean_std[1]} \\t\\ttime {time_mean_std[0]} \\t std {time_mean_std[1]}\")\n",
    "        print(i, \"\\t\", mcts_mean_std, best_seen_mean_std, \"\\tTime:\", time_mean_std)\n",
    "    else:\n",
    "        greedy_mean_std = np.around((np.mean(results[i]['result']), np.std(results[i]['result'])), 3)\n",
    "        greedy_time_mean_std = np.around((np.mean(results[i]['timestamps']), np.std(results[i]['timestamps'])), 3)\n",
    "        print(i, \"\\t\\t\", greedy_mean_std, \"\\t\\t\\tTime:\", greedy_time_mean_std)\n",
    "\n",
    "\n",
    "    \n",
    "#     print(i, np.mean(results[i]['mcts_result']), np.std(results[i]['mcts_result']))\n",
    "\n",
    "\n",
    "# for i in results:\n",
    "#     print(i, np.mean(results[i]['best_seen']), np.std(results[i]['best_seen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ReinforcementLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d39fadc1ce98843296dc726caa05b58b91b644660eb9af7f0d02a6740581fc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
