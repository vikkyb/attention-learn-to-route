{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\envs\\gnn_test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from utils import load_model\n",
    "from problems.tsp.problem_tsp import TSPDataset\n",
    "import time\n",
    "from mcts.mcts import MCTS_TSP\n",
    "from mcts.mcts_utils import evaluate_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS TO BE SET ###\n",
    "n_graphs = 10\n",
    "n_nodes = 20\n",
    "\n",
    "n_expansions = 100\n",
    "n_rollouts = 100\n",
    "eval_selection = \"best\"\n",
    "eval_rollout = \"best\"\n",
    "\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading model from pretrained/tsp_20/epoch-99.pt\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model 20 nodes and set temperature\n",
    "model, _ = load_model(F'pretrained/tsp_{n_nodes}/')\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "# Load test set graphs 20 nodes\n",
    "# If this block does not work, make sure you called:\n",
    "# python generate_data.py --problem all --name test --seed 1234\n",
    "with open(F\"data/tsp/tsp{n_nodes}_test_seed1234.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    dataset = TSPDataset(None, 0, 0, 0, None)\n",
    "    dataset.data = [torch.FloatTensor(row) for row in (data[0:0+10000])]\n",
    "    dataset.size = len(dataset.data)\n",
    "    graphs = []\n",
    "    for sample in dataset.data:\n",
    "        graphs.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph 0\n",
      "4.8627996\n",
      "Best tour seen 4.727939\n",
      "\n",
      "Graph 1\n",
      "5.3296275\n",
      "Best tour seen 5.174877\n",
      "\n",
      "Graph 2\n",
      "5.0051584\n",
      "Best tour seen 4.987064\n",
      "\n",
      "Graph 3\n",
      "5.063277\n",
      "Best tour seen 5.063277\n",
      "\n",
      "Graph 4\n",
      "4.360171\n",
      "Best tour seen 4.2643023\n",
      "\n",
      "Graph 5\n",
      "4.9554367\n",
      "Best tour seen 4.9554367\n",
      "\n",
      "Graph 6\n",
      "5.14106\n",
      "Best tour seen 4.830803\n",
      "\n",
      "Graph 7\n",
      "4.5489144\n",
      "Best tour seen 4.5489144\n",
      "\n",
      "Graph 8\n",
      "5.4290514\n",
      "Best tour seen 5.4290514\n",
      "\n",
      "Graph 9\n",
      "4.7659144\n",
      "Best tour seen 4.765914\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "total_len_best_seen = 0\n",
    "\n",
    "mcts_timestamps = []\n",
    "mcts_results = []\n",
    "best_seen_results = []\n",
    "\n",
    "for i in range(n_graphs):\n",
    "    graph = graphs[i]\n",
    "    graph_batch = graph[None] # Add batch dimension\n",
    "    tour = [0] # Start at first node, unconventional, TODO: fix this\n",
    "    mcts_20_nodes = MCTS_TSP(graph.numpy(), 0, n_expansions, n_rollouts, eval_selection=\"best\", eval_rollout=\"mean\")\n",
    "    t_s = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model.embedder(model._init_embed(graph_batch))\n",
    "\n",
    "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
    "        fixed = model._precompute(embeddings)\n",
    "        for visit in range(graph.shape[0] - 1):\n",
    "            tour_tensor = torch.tensor(tour).long()\n",
    "            if len(tour_tensor) == 0:\n",
    "                step_context = model.W_placeholder\n",
    "            else:\n",
    "                step_context = torch.cat((embeddings[0, tour_tensor[0]],\n",
    "                                        embeddings[0, tour_tensor[-1]]), -1)\n",
    "            query = fixed.context_node_projected + model.project_step_context(step_context[None, None, :])\n",
    "            mask = torch.zeros(graph_batch.shape[1], dtype=torch.uint8) > 0\n",
    "            mask[tour_tensor] = 1\n",
    "            mask = mask[None, None, :]\n",
    "\n",
    "            log_p, _ = model._one_to_many_logits(query, fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key, mask)\n",
    "            p = torch.softmax(log_p / temperature, -1)[0, 0]\n",
    "            assert (p[tour_tensor] == 0).all()\n",
    "            assert (p.sum() - 1).abs() < 1e-5\n",
    "            p = p.numpy()\n",
    "            mcts_20_nodes.update_priors(p)\n",
    "            next_node = mcts_20_nodes.mcts_decide()\n",
    "            # print(\"N children\", mcts_20_nodes.root._children.keys())\n",
    "            # print(p)\n",
    "            tour.append(next_node)\n",
    "            mcts_20_nodes.move_to(next_node)\n",
    "        t_e = time.perf_counter()\n",
    "        tour.append(0) # Return to the starting position\n",
    "        tour_len = evaluate_tour(graph.numpy(), tour)\n",
    "        mcts_results.append(tour_len)\n",
    "        best_seen_results.append(mcts_20_nodes.best_seen_length)\n",
    "        mcts_timestamps.append(t_e - t_s)\n",
    "        print(\"\\nGraph\", i)\n",
    "        print(evaluate_tour(graph.numpy(), tour))\n",
    "        print(\"Best tour seen\", mcts_20_nodes.best_seen_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MCTS results 4.946141\n",
      "Average best seen results 4.874758\n",
      "Average duration 7.104339689999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Average MCTS results\", np.mean(mcts_results))\n",
    "print(\"Average best seen results\", np.mean(best_seen_results))\n",
    "print(\"Average duration\", np.mean(mcts_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"mcts_result\" : mcts_results,\n",
    "    \"best_seen_results\" : best_seen_results,\n",
    "    \"mcts_timestamps\" : mcts_timestamps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/20_10_100_100_best_best.pkl\n"
     ]
    }
   ],
   "source": [
    "save_string = F\"experiments/{n_nodes}_{n_graphs}_{n_expansions}_{n_rollouts}_{eval_selection}_{eval_rollout}.pkl\"\n",
    "# print(save_string)\n",
    "with open(save_string, \"wb\") as f:\n",
    "    pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('gnn_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f490549c0cd5f8fedcc913b22aef81f15eaa7aa60d2e73329ed2fb30e9ea331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
